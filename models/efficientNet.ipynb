{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN mit EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1' #Kommentieren Sie diese Zeile aus, falls Sie ihre GPU benutzen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26948 files belonging to 2 classes.\n",
      "Found 6648 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras\n",
    "\n",
    "from functions import create_tf_dataSet\n",
    "from functions import upload_tensorboard\n",
    "dataset_path = r\"C:\\Users\\nilss\\Sets\\DataSet_v4 _train_aug\"\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "train_set = create_tf_dataSet(\n",
    "    path=dataset_path+\"/train\",\n",
    "    img_size=IMG_SIZE,\n",
    "    batch_size=32\n",
    "    )\n",
    "\n",
    "validation_set = create_tf_dataSet(\n",
    "    path=dataset_path+\"/validation\",\n",
    "    img_size=IMG_SIZE,\n",
    "    batch_size=32\n",
    ")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "efficientNet_layer = tf.keras.applications.EfficientNetB3(include_top=False) # iclude_top=False, spezialisierte Layer werden entfernt.\n",
    "efficientNet_layer.trainable = False # Die Gewichte sindgefrohren, sie sind nämlich schon sehr fein abgestimmt.\n",
    "\n",
    "# Input Layer erstellen\n",
    "inputs = tf.keras.layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "\n",
    "# Daten werden direkt an EfficientNet weitergegeben, es findet keine Data Augmentation mit der Keras API statt.\n",
    "# Für EfficientNet ist keine Normalisation notwendig.\n",
    "x= efficientNet_layer(inputs)\n",
    "# Pooling zur Verringerung der Parameter.\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "\n",
    "# Für diesen Feature-Extractor, kommt direkt nach EfficientNet bereits das Output-Neuron.\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\",)(x)\n",
    "\n",
    "# Erstellen des Modells.\n",
    "efficientNet_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def focal_loss(gamma=2., alpha=.25):\n",
    "#\t def focal_loss_fixed(y_true, y_pred):\n",
    "#\t\t pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#\t\t pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#\t\t return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1+K.epsilon())) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "#\t return focal_loss_fixed\n",
    "# aus https://github.com/mkocabas/focal-loss-keras/blob/master/focal_loss.py\n",
    "\n",
    "\n",
    "efficientNet_model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "        \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    \n",
    "    metrics=\n",
    "            # [keras.metrics.Precision(thresholds=[0.253]),keras.metrics.Recall(thresholds=[0.253]),]\n",
    "            [tf.keras.metrics.Recall(),tf.keras.metrics.Precision()],\n",
    "                \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb3 (Functional)  (None, None, None, 1536)  10783535 \n",
      "                                                                 \n",
      " global_average_pooling_laye  (None, 1536)             0         \n",
      " r (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 1537      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,785,072\n",
      "Trainable params: 1,537\n",
      "Non-trainable params: 10,783,535\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "efficientNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      "Epoch 1/20\n",
      "843/843 [==============================] - 1367s 2s/step - loss: 0.6045 - precision: 0.1451 - recall: 0.3564 - val_loss: 0.1898 - val_precision: 0.0963 - val_recall: 0.2719\n",
      "Epoch 2/20\n",
      "843/843 [==============================] - 1880s 2s/step - loss: 0.5437 - precision: 0.1698 - recall: 0.4766 - val_loss: 0.2274 - val_precision: 0.0911 - val_recall: 0.3947\n",
      "Epoch 3/20\n",
      "843/843 [==============================] - 2486s 3s/step - loss: 0.5227 - precision: 0.1806 - recall: 0.5085 - val_loss: 0.1918 - val_precision: 0.1105 - val_recall: 0.3509\n",
      "Epoch 4/20\n",
      "843/843 [==============================] - 2492s 3s/step - loss: 0.4999 - precision: 0.1964 - recall: 0.5521 - val_loss: 0.1742 - val_precision: 0.1164 - val_recall: 0.3246\n",
      "Epoch 5/20\n",
      "843/843 [==============================] - 2488s 3s/step - loss: 0.4875 - precision: 0.2017 - recall: 0.5691 - val_loss: 0.1778 - val_precision: 0.1079 - val_recall: 0.3246\n",
      "Epoch 6/20\n",
      "843/843 [==============================] - 2498s 3s/step - loss: 0.4821 - precision: 0.2076 - recall: 0.5691 - val_loss: 0.1821 - val_precision: 0.1076 - val_recall: 0.3333\n",
      "Epoch 7/20\n",
      "843/843 [==============================] - 2502s 3s/step - loss: 0.4720 - precision: 0.2089 - recall: 0.5766 - val_loss: 0.1849 - val_precision: 0.1074 - val_recall: 0.3421\n",
      "Epoch 8/20\n",
      "843/843 [==============================] - 2500s 3s/step - loss: 0.4606 - precision: 0.2203 - recall: 0.6117 - val_loss: 0.1810 - val_precision: 0.1084 - val_recall: 0.3509\n",
      "Epoch 9/20\n",
      "843/843 [==============================] - 2493s 3s/step - loss: 0.4634 - precision: 0.2109 - recall: 0.5915 - val_loss: 0.2042 - val_precision: 0.1064 - val_recall: 0.4211\n",
      "Epoch 10/20\n",
      "843/843 [==============================] - 2501s 3s/step - loss: 0.4560 - precision: 0.2222 - recall: 0.6128 - val_loss: 0.2031 - val_precision: 0.1028 - val_recall: 0.4123\n",
      "Epoch 11/20\n",
      "843/843 [==============================] - 2537s 3s/step - loss: 0.4455 - precision: 0.2231 - recall: 0.6213 - val_loss: 0.2187 - val_precision: 0.0959 - val_recall: 0.4474\n",
      "Epoch 12/20\n",
      "843/843 [==============================] - 2498s 3s/step - loss: 0.4428 - precision: 0.2223 - recall: 0.6223 - val_loss: 0.1838 - val_precision: 0.1069 - val_recall: 0.3684\n",
      "Epoch 13/20\n",
      "843/843 [==============================] - 2502s 3s/step - loss: 0.4428 - precision: 0.2207 - recall: 0.6181 - val_loss: 0.1970 - val_precision: 0.0991 - val_recall: 0.3947\n",
      "Epoch 14/20\n",
      "843/843 [==============================] - 2512s 3s/step - loss: 0.4396 - precision: 0.2285 - recall: 0.6223 - val_loss: 0.1672 - val_precision: 0.1080 - val_recall: 0.3333\n",
      "Epoch 15/20\n",
      "843/843 [==============================] - 2489s 3s/step - loss: 0.4322 - precision: 0.2275 - recall: 0.6309 - val_loss: 0.1801 - val_precision: 0.1076 - val_recall: 0.3596\n",
      "Epoch 16/20\n",
      "843/843 [==============================] - 2482s 3s/step - loss: 0.4320 - precision: 0.2259 - recall: 0.6426 - val_loss: 0.1717 - val_precision: 0.1038 - val_recall: 0.3333\n",
      "Epoch 17/20\n",
      "843/843 [==============================] - 1811s 2s/step - loss: 0.4224 - precision: 0.2377 - recall: 0.6543 - val_loss: 0.1717 - val_precision: 0.1037 - val_recall: 0.3421\n",
      "Epoch 18/20\n",
      "843/843 [==============================] - 1394s 2s/step - loss: 0.4218 - precision: 0.2359 - recall: 0.6543 - val_loss: 0.1645 - val_precision: 0.1012 - val_recall: 0.3070\n",
      "Epoch 19/20\n",
      "843/843 [==============================] - 1396s 2s/step - loss: 0.4277 - precision: 0.2283 - recall: 0.6479 - val_loss: 0.2094 - val_precision: 0.0937 - val_recall: 0.4298\n",
      "Epoch 20/20\n",
      "843/843 [==============================] - 1397s 2s/step - loss: 0.4123 - precision: 0.2455 - recall: 0.6755 - val_loss: 0.1773 - val_precision: 0.1015 - val_recall: 0.3509\n"
     ]
    }
   ],
   "source": [
    "#Hier wird das Modell trainiert.\n",
    "history = efficientNet_model.fit(\n",
    "                    train_set,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=len(train_set),\n",
    "                    validation_data=validation_set,\n",
    "                    validation_steps=int(len(validation_set)),\n",
    "                    class_weight={0:1,1:10},\n",
    "                    \n",
    "                    callbacks=[upload_tensorboard('',''),] \n",
    "                    )\n",
    "\n",
    "               \n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNet_model.save_weights('model_weights\\efficientNet_weights/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "283ef8891ff4bf443aa128a25cf2888f5af3851caf26729798254c68c875a2e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
